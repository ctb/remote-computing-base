[["index.html", "Introduction to Remote Computing 1 Overview 1.1 Introductory skills 1.2 Intermediate skills 1.3 Advanced skills", " Introduction to Remote Computing C. Titus Brown, Saranya Canchi, Amanda Charbonneau, Marisa Lim, Abhijna Parigi, Pamela Reynolds, and Nick Ulle. 2021-08-03 1 Overview 1.1 Introductory skills Workshop 1: Introduction to the UNIX Command Line - Tues Aug 3 Workshop 2: Creating and modifying text files on remote computers - Wed Aug 4 1.2 Intermediate skills Workshop 3: Connecting to remote computers with ssh - Tues Aug 10 Workshop 4: Running programs on remote computers and retrieving the results - Th Aug 12 Workshop 5: Installing software on remote computers with conda - Fri Aug 13 Workshop 6: Structuring your projects for current and future you - Tues Aug 17 Workshop 7: Automating your analyses and executing long-running analyses on remote computers - Th Aug 19 Workshop 8: Keeping track of your files with version control - Tues Aug 24 1.3 Advanced skills Workshop 9: Automating your analyses with the snakemake workflow system - Wed Aug 25 Workshop 10: Executing large analyses on HPC clusters with slurm - Th Aug 26 Workshop 11: Making use of on-demand “cloud” computers from Amazon Web Services - Tues Aug 31 "],["introduction-to-the-unix-command-line.html", "2 Introduction to the UNIX Command Line 2.1 Introduction to UNIX 2.2 Navigation 2.3 Viewing &amp; Searching 2.4 File Manipulation 2.5 Some final notes", " 2 Introduction to the UNIX Command Line This two hour workshop will introduce attendees to the UNIX command line, which is the main way to interact with remote computers. We will cover computing concepts, file systems and directory structure, and some of the most important commands for working with remote computers. Today and tomorrow we’ll be using an interactive Web site running on a binder. To start your binder, please click on the “launch” button below; it will take up to a minute to start. NOTE: This lesson was adapted from Data Carpentry’s Introduction to the Command Line for Genomics lesson and the Lab for Data Intensive Biology’s Advanced Beginner/Intermediate Shell workshop. 2.1 Introduction to UNIX 2.1.1 Learning Goals visualize file/directory structures understand basic shell vocabulary gain exposure to the syntax of shell &amp; shell scripting look at the contents of a directory find features of commands with man commands: pwd, ls, cd, man 2.1.1.1 What is the shell and what is the terminal? The shell is a computer program that uses a command line interface (CLI) to give commands made by your keyboard to your operating system. Most people are used to interacting with a graphic user interface (GUI), where you can use a combination of your mouse and keyboard to carry out commands on your computer. We can use the shell through a terminal program. Everything we can do using our computer GUI, we can do in the shell. We can open programs, run analyses, create documents, delete files and create folders. We should note that folders are called directories at the command line. For all intents and purposes they can be used interchangeably but if you’d like more information please see “The folder metaphor” section of Wikipedia. The ease of getting things done via the shell will increase with your exposure to the program. Go ahead and open a new terminal window in binder by clicking on “Terminal”. When we open up terminal in binder we will see a a line of text. This is a prompt statement. It can tell us useful things such as the name of the directory we are currently in, our username, or what computer we are currently running terminal on. Let’s take a look around. First, we can use the print working directory command see what directory we are currently located in. pwd This gives us the absolute path to the directory where we are located. An absolute path shows the complete series of directories you need to locate either a directory or a file starting from the root directory of your computer. What is the root? A useful way to start thinking about directories and files is through levels. At the highest level of your computer, you have the root directory. Everything that is contained in your computer is located in directories below your root directory. We can also look at the contents of the directory by using the ls (“list”) command: ls This command prints out a list of files and directories that are located in our current working directory. We’ve preloaded some data into the binder, so we have a subdirectory data/ that we can look at. To change the working directory, we need to use the cd (“change directory”) command. Let’s move into the data directory. cd data Let’s have a look around. ls We can see the following files: MiSeq Slide1.jpg hello.sh nano1.png README.md gvng.jpg nano2.png However, this directory contains more than the eye can see! To show hidden files we can use the -a option. ls -a We will see the following: . MiSeq Slide1.jpg hello.sh nano1.png .. README.md gvng.jpg .hidden nano2.png Three new items pop up ., .. and .hidden. Using options with our commands allows us to do a lot! But how did we know to add -a after ls? Most commands offer a --help. Let’s look at the available options that ls has: ls --help Here we see a long list of options. Each option will allow us to do something different. CHALLENGE Try to find the option that allows you to differentiate between directories and executable files when using ls. Hint: look for the word classify. (You can also look at the ls man page if you prefer! We can also combine commands: ls -aFl This combination of options will list all the contents of the directory and differentiate between file types. 2.2 Navigation 2.2.1 Learning Goals paths look at the contents of files perform functions outside of the directory you are in intro to the wildcard expression: * copy, move and remove files create and remove directories understand the structure of commands commands: cat, cp, mv, rm, mkdir Now we have seen how to navigate around our computers and seeing what is located in the directory we are. But some of the beauty of the shell is that we can execute activities in locations that we are not currently in. To do this we can either use an absolute path or a relative path. A relative path is the path to another directory from the the one you are currently in. Navigate into the tmp1 directory located in the .hidden directory. cd .hidden/tmp1 Here we see two files notit.txt and thisinnotit.txt. We can see what is in the directories using the cat command which concatenates and prints the content of the file we list. cat thisinnotit.txt This is not the text file you&#39;re looking for NOTE - you can use TAB to do filename completion, so if you type cat this and then press your Tab key once, it will autocomplete if there is a unique match. If there is more than one match, the first Tab will do nothing, and the second will show all the possible matches. Let’s see what else is in the other tmp directories: ls ../tmp2 and we can see the contents of tmp3 ls ../tmp3 So, even though we are in the tmp1/ directory, we can see what is in other directories by using the relative path to the directory of interest. Note we can also use absolute paths too. You may have noticed the ../ this is how to get to the directory above the one you are currently located in. Note: in this case, we have access to the RStudio file browser, too, which is really nice. But in the future we won’t. So we can use the file browser today, but on Farm we’ll have to get by with just the command line interface and no other interface! CHALLENGE: Use the absolute path to list the files in the tmp2 directory. Wouldn’t it be nice to see the contents of all the tmp directories at once? We can use a regular expression to capture a sequence of characters (like the numbers 1, 2 and 3 at the end of the tmp directories). We can use the wild card character *, which expands to match any amount of characters. ls ../tmp* ../tmp1: notit.txt thisinnotit.txt ../tmp2: anotherfile.txt ../tmp3: closebutnotit.txt youfoundit.txt So, even though we are in the tmp1 directory we can use a relative path. We are quite used to moving, copying and deleting files using a GUI. All of these functions can be carried out at the command line with the following commands: Copy files with the cp command by specifying a file to copy and the location of the copied file. Here we will copy the thisinnotit.txt into the file thisisacopy.txt. cp thisinnotit.txt thisisacopy.txt The syntax for the copy command is cp &lt;source_file&gt; &lt;destination_file&gt;. Using this syntax we can copy files to other directories as well: cp thisinnotit.txt ../tmp2 If we navigate to the tmp2 directory and list the files that are in it we will see the thisinnotit.txt file has been copied to the tmp2 directory. cd ../tmp2 ls -l CHALLENGE: Use the mv command to move the thisinnotit.txt file from tmp2 to tmp3. Once we know how to copy and move files, we can also copy and move directories. We can create new directories with the command mkdir. Let’s make a new directory called tmp4 cd ../ mkdir tmp4 ls -l The shell is quite powerful and can create multiple directories at once. It can create multiple directories in the current working directory: mkdir tmp5 tmp6 ls -l or it can create a series of directories on top of one another: mkdir -p how/deep/does/the/rabbit/hole/go We can use tab complete to get to the go directory. Type cd h then hit tab. If you hit tab enough times your command will eventually read: cd how/deep/does/the/rabbit/hole/go/ You can see that we’ve created a bit of a monster directory structure… CHALLENGE: Navigate to the data directory and use the rm command to remove the how directory and all its contents. This nicely hints at the power of the shell - you can do certain things (in this case, create a nested hierarchy of directories) much more easily in the shell. But that power cuts both ways - you can also mess things up more easily in the shell! 2.3 Viewing &amp; Searching 2.3.1 Learning Goals looking inside files search for keywords within files commands: less, head, tail, grep A big part of data science is making sure what you expect in a particular file is what you have in that file. There are a few ways to look at the contents of a file. We’ve already seen how to print the entirety of a file to the stdout of our cat command. We can also look at files using the less command. Less is a safe way of looking at the contents of a file without the ability to change it. (We’ll talk more about text files and editing them in the second workshop!) Starting from the data/ directory in our home directory cd ~/data/ let’s look at some sequence data in a fastq file format. cd MiSeq less F3D0_S188_L001_R1_001.fastq We can see a bunch of sequence data! Use the up, down, left and right arrows to look through the folder a bit. Then press q to quit less. A lot of the time we want to know if a file contains what we expect. Many of the sequence files in this directory have the file ending .fastq. We expect these files to contain information in a particular format throughout the file with four lines of information for each sequence string. Looking through a million line file using less will take a long time. Rather than manually looking through the file we can print only a portion of the files contents to the terminal: head F3D0_S188_L001_R1_001.fastq @M00967:43:000000000-A3JHG:1:1101:18327:1699 1:N:0:188 NACGGAGGATGCGAGCGTTATCCGGATTTATTGGGTTTAAAGGGTGCGTAGGCGGCCTGCCAAGTCAGCGGTAAAATTGCGGGGCTCAACCCCGTACAGCCGTTGAAACTGCCGGGCTCGAGTGGGCGAGAAGTATGCGGAATGCGTGGTGTAGCGGTGAAATGCATAGATATCACGCAGAACCCCGATTGCGAAGGCAGCATACCGGCGCCCTACTGACGCTGAGGCACGAAAGTGCGGGGATCAAACAG + #&gt;&gt;AABABBFFFGGGGGGGGGGGGGGGGHHHHHHHGGGHHHHHGHGGGGGGGHGGGGGGHHHHHHHHHHGGGGGHHHHGHGGGGGGHHBGHGDGGGGGHHHGGGGHHHHHHHHGGGGGHG@DHHGHEGGGGGGBFGGEGGGGGGGG.DFEFFFFFFFDCFFFFFFFFFFFFFFFFFFFFFFFFFFDFDFFFEFFCFF?FDFFFFFFFFAFFFFFFFFFFFBDDFFFFFEFADFFFFFBAFFFA?EFFFBFF @M00967:43:000000000-A3JHG:1:1101:14069:1827 1:N:0:188 TACGGAGGATGCGAGCGTTATCCGGATTTATTGGGTTTAAAGGGTGCGTAGGCGGCCTGCCAAGTCAGCGGTAAAATTGCGGGGCTCAACCCCGTACAGCCGTTGAAACTGCCGGGCTCGAGTGGGCGAGAAGTATGCGGAATGCGTGGTGTAGCGGTGAAATGCATAGATATCACGCAGAACCCCGATTGCGAAGGCAGCATACCGGCGCCCTACTGACGCTGAGGCACGAAAGTGCGGGGATCAAACAG + 3AA?ABBDBFFBEGGEGGGGAFFGGGGGHHHCGGGGGGHFGHGGCFDEFGGGHGGGEGF1GGFGHHHHHGGEGGHHHHHFGGGGGGHHHHHGGGGCDDGHHGGGFHHHHHHHHCD@CCHGGGGHEHGGG@GFGGGGGGG@BGGGEGCEBFFFBFFB;9@EFFFEFFFFFFFFFFFFAFBBBFFFFFBBBFFFFBBBFFFFFFFFFFFBBBBBBBFFFFFFFFFDDFAFFFFF.AF9/FBBBBB.EAFFE?F @M00967:43:000000000-A3JHG:1:1101:18044:1900 1:N:0:188 TACGGAGGATGCGAGCGTTGTCCGGAATCACTGGGCGTAAAGGGCGCGTAGGCGGTTTAATAAGTCAGTGGTGAAAACTGAGGGCTCAACCCTCAGCCTGCCACTGATACTGTTAGACTTGAGTATGGAAGAGGAGAATGGAATTCCTAGTGTAGCGGTGAAATGCGTAGATATTAGGAGGAACACCAGTGGCGAAGGCGATTCTCTGGGCCAAGACTGACGCTGAGGCGCGAAAGCGTGGGGAGCAAACA head prints the first ten lines of a file out onto your screen. We can look at the last ten lines of a file using the tail command: tail F3D0_S188_L001_R1_001.fastq We can see that our fastq files look a lot different than the fasta files: head HMP_MOCK.v35.fasta &gt;A.baumannii.1 TGGGGAATATTGGACAATGGGGGGAACCCTGATCCAGCCATGCCGCGTGTGTGAAGAAGGCCTTATGGTTGTAAAGCACTTTAAGCGAGGAGGAGGCTACTTTAGTTAATACCTAGAGATAGTGGACGTTACTCGCAGAATAAGCACCGGCTAACTCTGTGCCAGCAGCCGCGGTAATACAGAGGGTGCGAGCGTTAATCGGATTTACTGGGCGTAAAGCGTGCGTAGGCGGCTTATTAAGTCGGATGTGAAATCCCCGAGCTTAACTTGGGAATTGCATTCGATACTGGTGAGCTAGAGTATGGGAGAGGATGGTAGAATTCCAGGTGTAGCGGTGAAATGCGTAGAGATCTGGAGGAATACCGATGGCGAAGGCAGCCATCTGGCCTAATACTGACGCTGAGGTACGAAAGCATGGGGAGCAAACAGGATTAGATACCCTGGTAGTCCATGCCGTAAACGATGTCTACTAGCCGTTGGGGCCTTTGAGGCTTTAGTGGCGCAGCTAACGCGATAAGTAGACCGCCTGGGGAGTACGGTC &gt;A.odontolyticus.1 TGGGGAATATTGCACAATGGGCGAAAGCCTGATGCAGCGACGCCGCGTGAGGGATGGAGGCCTTCGGGTTGTAAACCTCTTTCGCTCATGGTCAAGCCGCAACTCAAGGTTGTGGTGAGGGTAGTGGGTAAAGAAGCGCCGGCTAACTACGTGCCAGCAGCCGCGGTAATACGTAGGGCGCGAGCGTTGTCCGGAATTATTGGGCGTAAAGGGCTTGTAGGCGGTTGGTCGCGTCTGCCGTGAAATCCTCTGGCTTAACTGGGGGCGTGCGGTGGGTACGGGCTGACTTGAGTGCGGTAGGGGAGACTGGAACTCCTGGTGTAGCGGTGGAATGCGCAGATATCAGGAAGAACACCGGTGGCGAAGGCGGGTCTCTGGGCCGTTACTGACGCTGAGGAGCGAAAGCGTGGGGAGCGAACAGGATTAGATACCCTGGTAGTCCACGCTGTAAACGTTGGGCACTAGGTGTGGGGGCCACCCGTGGTTTCTGCGCCGTAGCTAACGCTTTAAGTGCCCCGCCTGGGGAGTACGGCC &gt;B.cereus.1 TAGGGAATCTTCCGCAATGGACGAAAGTCTGACGGAGCAACGCCGCGTGAGTGATGAAGGCTTTCGGGTCGTAAAACTCTGTTGTTAGGGAAGAACAAGTGCTAGTTGAATAAGCTGGCACCTTGACGGTACCTAACCAGAAAGCCACGGCTAACTACGTGCCAGCAGCCGCGGTAATACGTAGGTGGCAAGCGTTATCCGGAATTATTGGGCGTAAAGCGCGCGCAGGTGGTTTCTTAAGTCTGATGTGAAAGCCCACGGCTCAACCGTGGAGGGTCATTGGAAACTGGGAGACTTGAGTGCAGAAGAGGAAAGTGGAATTCCATGTGTAGCGGTGAAATGCGTAGAGATATGGAGGAACACCAGTGGCGAAGGCGACTTTCTGGTCTGTAACTGACACTGAGGCGCGAAAGCGTGGGGAGCAAACAGGATTAGATACCCTGGTAGTCCACGCCGTAAACGATGAGTGCTAAGTGTTAGAGGGTTTCCGCCCTTTAGTGCTGAAGTTAACGCATTAAGCACTCCGCCTGGGGAGTACGGCC &gt;B.vulgatus.1 TGAGGAATATTGGTCAATGGGCGCAGGCCTGAACCAGCCAAGTAGCGTGAAGGATGACTGCCCTATGGGTTGTAAACTTCTTTTATAAAGGAATAAAGTCGGGTATGGATACCCGTTTGCATGTACTTTATGAATAAGGATCGGCTAACTCCGTGCCAGCAGCCGCGGTAATACGGAGGATCCGAGCGTTATCCGGATTTATTGGGTTTAAAGGGAGCGTAGATGGATGTTTAAGTCAGTTGTGAAAGTTTGCGGCTCAACCGTAAAATTGCAGTTGATACTGGATATCTTGAGTGCAGTTGAGGCAGGCGGAATTCGTGGTGTAGCGGTGAAATGCTTAGATATCACGAAGAACTCCGATTGCGAAGGCAGCCTGCTAAGCTGCAACTGACATTGAGGCTCGAAAGTGTGGGTATCAAACAGGATTAGATACCCTGGTAGTCCACACGGTAAACGATGAATACTCGCTGTTTGCGATATACGGCAAGCGGCCAAGCGAAAGCGTTAAGTATTCCACCTGGGGAGTACGCCG &gt;B.vulgatus.2 TGAGGAATATTGGTCAATGGGCGAGAGCCTGAACCAGCCAAGTAGCGTGAAGGATGACTGCCCTATGGGTTGTAAACTTCTTTTATAAAGGAATAAAGTCGGGTATGGATACCCGTTTGCATGTACTTTATGAATAAGGATCGGCTAACTCCGTGCCAGCAGCCGCGGTAATACGGAGGATCCGAGCGTTATCCGGATTTATTGGGTTTAAAGGGAGCGTAGATGGATGTTTAAGTCAGTTGTGAAAGTTTGCGGCTCAACCGTAAAATTGCAGTTGATACTGGATATCTTGAGTGCAGTTGAGGCAGGCGGAATTCGTGGTGTAGCGGTGAAATGCTTAGATATCACGAAGAACTCCGATTGCGAAGGCAGCCTGCTAAGCTGCAACTGACATTGAGGCTCGAAAGTGTGGGTATCAAACAGGATTAGATACCCTGGTAGTCCACACGGTAAACGATGAATACTCGCTGTTTGCGATATACGGCAAGCGGCCAAGCGAAAGCGTTAAGTATTCCACCTGGGGAGTACGCCG Each sequence entry for a fasta formatted file contains only two lines of information for each sequence string. Another useful thing to do is to be able to search the contents of files for a particular string of characters you would like to find. Let’s say you’d like to find the sequence CATTAG in your files. We can use the file pattern searcher grep to look for our favorite sequence: grep CATTAG F3D0_S188_L001_R2_001.fastq We can also use the wildcard regular expression to search CATTAG in all of the fastq files located in our current working directory: grep CATTAG *.fastq CHALLENGE: What line does CATTAG occur on in F3D141_S207_L001_R1_001.fastq? (HINT: Use grep --help to search for grep options related to line number) 2.4 File Manipulation 2.4.1 Learning Goals commands for, basename, echo 2.4.2 Renaming a bunch of files Let’s make sure we’re in the right directory- the one that contains all of our data files. cd ~/data/MiSeq For our first task, let’s pretend that we want to rename all of the fastq files to be .fq files instead (this is a surprisingly useful specific skill, even if you can’t immediately think of why you would want to do that!). Here, we get to use two of my favorite commands - ‘for’ and ‘basename’. for lets you do something to every file in a list. To see it in action: for i in *.fastq do echo $i done This is running the command echo for every value of the variable ‘i’, which is set (one by one) to all the values in the expression *.fastq. If we want to get rid of the extension ‘.fastq’, we can use the basename command: for i in *.fastq do basename $i .fastq done Now, this doesn’t actually rename the files - it just prints out the name, with the suffix ‘.fastq’ removed. To rename the files, we need to capture the new name in a variable: for i in *.fastq do newname=$(basename $i .fastq).fq echo $newname done What $( ... ) does is run the command in the middle, and then replace the $( ) with the output of running the command. Now we have the old name ($i) and the new name ($newname) and we’re ready to write the rename command – for i in *.fastq do newname=$(basename $i .fastq).fq echo mv $i $newname done Question: why did I put echo here? Now that we’re pretty sure it all looks good, let’s run it for realz: for i in *.fastq do newname=$(basename $i .fastq).fq mv $i $newname done and voila, we have renamed all the files! Side note: you may see backquotes used instead of $(...). It does the same thing but is trickier to get right, so we teach $(...) instead of `. 2.5 Some final notes This lesson focused on file and directory exploration because that’s something everyone needs to know, and all these commands will work on pretty much any computer that is running a UNIX compatible shell (including Mac OS X and Windows Subsystem for Linux). We’ll get into a broader range of tasks soon, promise! The binder and this documentation page will stay working for the foreseeable future, so please feel free to come back and revisit some of these commands! We will explore more UNIX commands over the next few workshops! Google (and especially stackoverflow) is your friend! Use Internet search whenever you have questions about what a command does, or what commands to use to achieve a particular tasks. "],["creating-and-modifying-text-files-on-remote-computers.html", "3 Creating and modifying text files on remote computers 3.1 Text files vs other files 3.2 Big Powerful Editors 3.3 Other editor choices that we can’t use right now, but that come recommended 3.4 Other ways to create, edit, filter, and modify files 3.5 Working with csv files 3.6 Remote vs local, and why editors?", " 3 Creating and modifying text files on remote computers @CTB Add BlurB Hre As with the first workshop introducing the UNIX command line, we’ll be using an interactive Web site running on a binder. To start your binder, please click on the “launch” button below; it will take up to a minute to start. 3.1 Text files vs other files Text files are a fairly narrow but very important subset of the kinds of files that we will work with in data science. Text files are, loosely defined, files that are human-readable without any special machine interpretation needed - such as text-only e-mails, CSV files, configuration files, and Python and R scripts. The list above is interesting, because it makes the point that just because a human can “read” the files doesn’t mean that they are intended for humans, necessarily. For example, CSV files can be more or less strictly defined in terms of formatting, and Python and R scripts still need to be valid Python or R code. DNA sequence data files like we saw yesterday are another case in point - it’s pretty rare (and a bad idea) to edit them manually, but you could if you really wanted to. The operational distinction really comes down to this: text files can be created, edited, changed, and otherwise manipulated with text-format based tools, like text editors, grep (which we saw yesterday), and other programs. Text files are a common and standard format that many tools can interact with. In comparison, binary files are files that need special programs to interact with them. Some of them are more standard than others - for example, Word files can be read or written by many programs. Images (JPG and PNG and…) can be manipulated by many programs as well. Zip files are another semi-standard format that can be manipulated by several different programs. The main thing is that you can’t just look at them with standard text-focused tools - and typically this is because binary files are meant to be used for different kinds of data than text. As a side note, one of the most important aspects of text files is that there are some really powerful tools for tracking changes to them, and collaboratively editing them - we’ll cover that in week @CTB, version control! 3.1.1 OK, OK, what does this all mean in practice? Let’s look at a simple text file - 2cities/README.md: cat 2cities/README.md As you may remember, ‘cat’ (short for ‘catenate’) displays the content of the file. This is a file in a format called Markdown, that is a lightly decorated text file with a title and so on. While it can be nicely formatted by an interpreting program (see @github link), it can also just be viewed and read with cat. This is different from the other file in 2cities/; take a look at what’s there: run, ls 2cities/ and you should see README.md book.txt.gz In this directory, there is one text file and one binary file. If you want to see if it’s a file type that UNIX recognizes you can run the file command, e.g. file 2cities/README.md will report that it’s ASCII text, while file 2cities/book.txt.gz will report that it’s “gzip compressed data”, which is a compressed data type. What do we do with that? 3.1.2 Working with gzipped files gzip is a common type of file, and all that it means is that it’s been compressed (made smaller) with the gzip program. Look at it’s file size first – ls -lh 2cities/book.txt.gz and you’ll see that it’s about 300k. You can uncompress a gzip file with gunzip; in this case, gunzip 2cities/book.txt.gz will produce 2cities/book.txt. CHALLENGE: what commands will tell you its file type and size? Yep, it’s almost 3 times bigger when it’s uncompressed! And it’s file type is “UTF-8 Unicode (with BOM) text, with CRLF line terminators” which is a fancy way of saying “text, supporting extended characters (unicode), and with both a carriage return (CR) and a line feed (LF) at the end of each line.” The important thing is that pretty much any text editor should be able to edit this kind of file. Let’s take a quick look at the beginning of the file with head: head 2cities/book.txt yep, looks like text! 3.1.3 Digression: file extensions are often meaningful (but don’t have to be) Couldn’t we have guessed at what these files were based on their names? Yes, the .md extension usually means it’s a text file with Markdown formatting, and the .gz extension typically means it’s a compressed file, and the .txt extension typically means it’s a text file. So you can read book.txt.gz to mean that it’s a text file that’s been compressed. But this isn’t guaranteed - it’s a convention, rather than a requirement. Many programs will actively “sniff” the file type by looking at the content (which is what file does), and you should never blindly trust the file type indicated by the extension. 3.1.4 Let’s edit this file! Let’s start with the pico editor. Pico and its sibling nano are simple text editors that let you get started, but are ultimately limited in their functionality. open file no mouse, just arrow keys and commands on bottom ctrl-x to exit if you change it, ctrl-x will ask if you want to save it. go ahead, change something in the first few lines ,and save it. does head report? Some basic navigation Long lines how to get help You can do a lot in these but as soon as you’re dealing with really large files, or many files, we suggest other editors. 3.2 Big Powerful Editors There are two fairly dominant editors that work at the command line. They’ve been around for decades, and they have many advocates who care for them with a near-religious fervor. We will demo them for you, and point you at learning resources for them, and then leave it up to you to pick one. (We’ll probably use nano for most of the work we do in these workshops.) 3.2.1 Big Powerful Editor 1: vi how to run how to navigate how to go to a specific line how to edit how to quit how to save @CTB how to learn 3.2.2 Big Powerful Editor 2: emacs how to run how to navigate how to go to a specific line how to edit how to quit how to save @CTB how to learn 3.3 Other editor choices that we can’t use right now, but that come recommended (point at twitter poll) NotePad++ VScode BBedit 3.4 Other ways to create, edit, filter, and modify files 3.4.1 Redirection and appending 3.4.2 The dumbest possible “editor” - cat 3.4.3 Piping and filtering grep cut wc -l 3.5 Working with csv files grep cut csvtk 3.6 Remote vs local, and why editors? take step back, talk about initial remote/local dichotomy what we’ve shown you is… these skills will become second nature if you use them, bcause they are foundational to everything you always want to know at least one local editor, I suggest learning vim what you use other than that is up to you and your prefs - pepole really like the windows/mac os x software above. "]]
